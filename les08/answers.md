## 1. В чем состоит задача кластеризации?

**Задача кластеризации** - это задача разбиения множества объектов на группы (кластеры) таким образом, чтобы:
- Объекты внутри одного кластера были **похожи** друг на друга
- Объекты из разных кластеров были **непохожи**

**Формальная постановка:**
Дано:
- Множество объектов X = {x₁, x₂, ..., xₙ}
- Функция расстояния между объектами d(xᵢ, xⱼ)

Найти: разбиение X на K непересекающихся подмножеств (кластеров) C₁, C₂, ..., Cₖ, которое оптимизирует некоторый критерий качества.

**Ключевая особенность:** обучение **без учителя** - истинные метки кластеров неизвестны.

## 2. Для каких целей используется кластеризация?

**Основные применения кластеризации:**

1. **Сегментация данных:**
   - Сегментация клиентов
   - Группировка пользователей по поведению
   - Выявление рыночных ниш

2. **Поиск аномалий:**
   - Обнаружение мошеннических операций
   - Выявление неисправностей оборудования

3. **Сжатие данных:**
   - Векторное квантование
   - Уменьшение размерности

4. **Подготовка данных:**
   - Создание новых признаков для обучения с учителем
   - Стратификация данных

5. **Научные исследования:**
   - Классификация видов в биологии
   - Группировка документов по темам
   - Анализ генетических данных

## 3. Алгоритм кластеризации Ллойда (K-средних)

**Алгоритм K-средних (K-means)** - итеративный алгоритм, минимизирующий внутрикластерную дисперсию.

**Шаги алгоритма:**

1. **Инициализация:** Случайно выбрать K центроидов

2. **Назначение кластеров:** Для каждого объекта найти ближайший центроид
   ```
   Для каждого xᵢ: cᵢ = argminⱼ ||xᵢ - μⱼ||²
   ```

3. **Обновление центроидов:** Пересчитать центроиды как среднее точек кластера
   ```
   Для каждого j: μⱼ = (1/|Cⱼ|) * Σ xᵢ, где xᵢ ∈ Cⱼ
   ```

4. **Повторение:** Повторять шаги 2-3 до сходимости (центроиды не меняются)

**Критерий качества (within-cluster sum of squares):**
```
J = Σⱼ Σ xᵢ ∈ Cⱼ ||xᵢ - μⱼ||²
```

## 4. Как выбрать количество кластеров для алгоритма K-средних

**Методы выбора числа кластеров K:**

1. **Метод локтя (Elbow Method):**
   - Строится график зависимости J(K) от K
   - Выбирается K в "точке локтя" - где уменьшение J резко замедляется
   ```
   J(K) = Σⱼ Σ xᵢ ∈ Cⱼ ||xᵢ - μⱼ||²
   ```

2. **Силуэтный анализ (Silhouette Analysis):**
   - Для каждого K вычисляется средний силуэтный коэффициент
   - Выбирается K с максимальным средним силуэтом
   - Силуэтный коэффициент для объекта:
     ```
     s(i) = (b(i) - a(i)) / max(a(i), b(i))
     ```
     где a(i) - среднее расстояние до объектов своего кластера,
     b(i) - среднее расстояние до объектов ближайшего другого кластера

3. **Gap Statistic:**
   - Сравнивает J(K) с ожидаемым J(K) для равномерного распределения
   - Выбирает K, максимизирующий разрыв (gap)

4. **Стабильность кластеризации:**
   - Анализ устойчивости кластеризации при разных инициализациях

## 5. Алгоритм DBSCAN

**DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** - алгоритм, основанный на плотности.

**Ключевые понятия:**
- **ε-окрестность:** Nε(x) = {y | d(x,y) ≤ ε}
- **Ядровой объект:** |Nε(x)| ≥ minPts
- **Прямая достижимость:** y достижим из x, если y ∈ Nε(x) и x - ядровой
- **Достижимость:** существует цепочка прямой достижимости

**Параметры:**
- **ε** - радиус окрестности
- **minPts** - минимальное количество точек в ε-окрестности

**Шаги алгоритма:**

1. **Поиск ядровых точек:** Найти все точки с ≥ minPts в ε-окрестности

2. **Построение кластеров:**
   - Для каждой необработанной ядровой точки создать новый кластер
   - Добавить все достижимые точки в кластер

3. **Обработка шума:** Точки, не вошедшие в кластеры, помечаются как шум

**Преимущества DBSCAN:**
- Не требует задания числа кластеров
- Находит кластеры произвольной формы
- Устойчив к выбросам
- Не зависит от порядка данных

**Недостатки:**
- Чувствительность к параметрам ε и minPts
- Плохо работает с данными разной плотности
- Зависит от метрики расстояния

**Пример на Python:**
```python
from sklearn.cluster import DBSCAN

dbscan = DBSCAN(eps=0.5, min_samples=5)
clusters = dbscan.fit_predict(X)

# clusters содержит метки: -1 для шума, 0,1,2... для кластеров
```