## 1. Какие типы машинного обучения вы знаете?

**Основные типы машинного обучения:**

1. **Обучение с учителем (Supervised Learning)**
   - Классификация
   - Регрессия

2. **Обучение без учителя (Unsupervised Learning)**
   - Кластеризация
   - Понижение размерности
   - Поиск ассоциативных правил

3. **С частичным привлечением учителя (Semi-supervised Learning)**

4. **С подкреплением (Reinforcement Learning)**

5. **Самообучение (Self-supervised Learning)**

## 2. Чем отличается обучение с учителем и без учителя?

| Характеристика | С учителем | Без учителя |
|----------------|------------|-------------|
| **Наличие меток** | Есть размеченные данные | Нет размеченных данных |
| **Цель** | Предсказание метки | Поиск структуры в данных |
| **Примеры задач** | Классификация, регрессия | Кластеризация, поиск аномалий |
| **Оценка качества** | Через сравнение с истинными метками | Через внутренние метрики |
| **Примеры алгоритмов** | Linear Regression, SVM | K-means, PCA |

## 3. Чем пакетное обучение отличается от динамического?

| Характеристика | Пакетное обучение | Динамическое обучение |
|----------------|-------------------|----------------------|
| **Обучение** | На всем наборе данных сразу | Постепенно, на новых данных |
| **Память** | Требует хранения всех данных | Может забывать старые данные |
| **Скорость** | Медленное обучение | Быстрое обновление |
| **Использование** | Статические данные | Потоковые данные |
| **Примеры** | Классическое ML | Online Learning |

## 4. Чем обучение на основе образцов отличается от обучения на основе модели?

**Обучение на основе образцов (Instance-based):**
- Запоминает обучающие данные
- Не строит явную модель
- Предсказание на основе похожих примеров
- Примеры: k-NN, метод ближайших соседей

**Обучение на основе модели (Model-based):**
- Строит параметрическую модель
- Обобщает закономерности из данных
- Отбрасывает обучающие данные после обучения
- Примеры: Linear Regression, Decision Trees

## 5. Что такое линейная регрессия?

**Линейная регрессия** - алгоритм для предсказания непрерывной целевой переменной на основе линейной зависимости от признаков.

**Математическая формула:**
```
y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε
```
где:
- y - целевая переменная
- β₀ - свободный член (intercept)
- β₁...βₙ - коэффициенты при признаках
- x₁...xₙ - признаки
- ε - ошибка

**Цель:** найти коэффициенты, минимизирующие ошибку предсказания.

## 6. Что такое градиентный спуск?

**Градиентный спуск** - итеративный алгоритм оптимизации для нахождения минимума функции.

**Принцип работы:**
1. Выбирается начальная точка (случайные веса)
2. Вычисляется градиент (направление наискорейшего роста)
3. Делается шаг в противоположном направлении
4. Процесс повторяется до сходимости

**Формула обновления весов:**
```
θ = θ - η * ∇J(θ)
```
где:
- θ - параметры модели
- η - скорость обучения (learning rate)
- ∇J(θ) - градиент функции стоимости

## 7. Как правильно обрабатывать категориальные признаки?

**Основные методы обработки:**

1. **One-Hot Encoding** - создание бинарных признаков для каждой категории
   ```python
   from sklearn.preprocessing import OneHotEncoder
   ```

2. **Label Encoding** - присвоение числовых меток категориям
   ```python
   from sklearn.preprocessing import LabelEncoder
   ```

3. **Ordinal Encoding** - для порядковых категорий с естественным порядком

4. **Target Encoding** - замена категории средним значением целевой переменной

5. **Frequency Encoding** - замена категории частотой ее появления

**Рекомендации:**
- Для линейных моделей использовать One-Hot Encoding
- Для tree-based моделей можно использовать Label Encoding
- Избегать произвольного порядка в кодировании

## 8. Что такое матрица корреляции?

**Матрица корреляции** - квадратная матрица, показывающая попарные корреляции между переменными.

**Значения коэффициента корреляции:**
- от -1 до 1
- 1: полная положительная корреляция
- -1: полная отрицательная корреляция  
- 0: отсутствие линейной зависимости

**Использование:**
- Анализ мультиколлинеарности
- Отбор признаков
- Исследование взаимосвязей в данных

```python
import pandas as pd
correlation_matrix = df.corr()
```

## 9. Что показывает метрика RMSE?

**RMSE (Root Mean Square Error)** - среднеквадратичная ошибка, показывает среднее отклонение предсказаний от истинных значений.

**Формула:**
```
RMSE = √(Σ(y_i - ŷ_i)² / n)
```

**Особенности:**
- Измеряется в тех же единицах, что и целевая переменная
- Сильно штрафует за большие ошибки (квадратичная функция)
- Чувствительна к выбросам
- Чем меньше значение, тем лучше модель

## 10. Что показывает метрика R²?

**R² (коэффициент детерминации)** - показывает долю дисперсии целевой переменной, объясненную моделью.

**Формула:**
```
R² = 1 - (SS_res / SS_tot)
```
где:
- SS_res - сумма квадратов остатков
- SS_tot - общая сумма квадратов

**Интерпретация:**
- от 0 до 1 (может быть отрицательной для плохих моделей)
- 1: идеальное предсказание
- 0: модель не лучше среднего значения
- Отрицательное значение: модель хуже среднего значения

**Особенности:**
- Не показывает абсолютную величину ошибки
- Увеличивается при добавлении признаков (даже бесполезных)