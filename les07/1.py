import sys
import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score

def load_data(filename):
    #–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV 
    df = pd.read_csv(filename, index_col="PassengerId")
    print("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
    print("–ü–µ—Ä–≤—ã–µ 7 —Å—Ç—Ä–æ–∫ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:\n")
    print(df.head(7))
    print()
    return df


def describe_data(df):
    #–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö 
    print("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö:")
    print(df.info())
    print()
    print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π:")
    print(df.isnull().sum())
    print()
    return df


def clean_data(df):
    #–£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ—á–∏—Å–ª–æ–≤—ã—Ö –∏ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ 
    df = df.drop(["Name", "Ticket", "Cabin"], axis=1)
    print("üßπ –£–¥–∞–ª–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏: Name, Ticket, Cabin (–Ω–µ –≤–ª–∏—è—é—Ç –Ω–∞–ø—Ä—è–º—É—é –Ω–∞ –≤—ã–∂–∏–≤–∞–Ω–∏–µ)")
    print()
    return df


def encode_sex(df):
    #–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–∞ 
    df["male"] = (df["Sex"] == "male").astype(int)
    df["female"] = (df["Sex"] == "female").astype(int)
    df = df.drop("Sex", axis=1)
    print("–ü—Ä–∏–∑–Ω–∞–∫ 'Sex' –∑–∞–º–µ–Ω—ë–Ω –Ω–∞ 'male' –∏ 'female'.")
    print()
    return df


def encode_embarked(df):
    #One-Hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ä—Ç–∞ –ø–æ—Å–∞–¥–∫–∏ 
    df = pd.get_dummies(df, columns=["Embarked"], prefix="Embarked", dummy_na=False)
    print("–ü—Ä–∏–∑–Ω–∞–∫ 'Embarked' –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω (One-Hot Encoding).")
    print(f"–î–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏: {', '.join([c for c in df.columns if 'Embarked_' in c])}")
    print()
    return df


def remove_nulls(df):
    #–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ 
    before = len(df)
    df = df.dropna()
    after = len(df)
    print(f"–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏: {before - after}")
    print()
    return df


def normalize_fare(df):
    #–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞ 'Fare' 
    scaler = StandardScaler()
    df["Fare_norm"] = scaler.fit_transform(df[["Fare"]])
    print("‚öñÔ∏è –ü—Ä–∏–∑–Ω–∞–∫ 'Fare' –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω (Fare_norm).")
    print()
    return df


def analyze_fare(df):
    #–†–∞–∑–Ω–∏—Ü–∞ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π 'Fare' –º–µ–∂–¥—É –≤—ã–∂–∏–≤—à–∏–º–∏ –∏ –ø–æ–≥–∏–±—à–∏–º–∏ 
    survived_mean = df[df["Survived"] == 1]["Fare"].mean()
    not_survived_mean = df[df["Survived"] == 0]["Fare"].mean()
    diff = survived_mean - not_survived_mean
    print(f"–†–∞–∑–Ω–∏—Ü–∞ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π 'Fare' (–≤—ã–∂–∏–≤—à–∏–µ - –ø–æ–≥–∏–±—à–∏–µ): {diff:.2f}")
    print()
    return diff


def plot_fare_hist(df):
    #–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–∏–ª–µ—Ç–∞ –¥–ª—è –≤—ã–∂–∏–≤—à–∏—Ö –∏ –ø–æ–≥–∏–±—à–∏—Ö 
    plt.figure(figsize=(8, 5))
    plt.hist(df[df["Survived"] == 0]["Fare"], bins=30, alpha=0.6, label="–ü–æ–≥–∏–±—à–∏–µ")
    plt.hist(df[df["Survived"] == 1]["Fare"], bins=30, alpha=0.6, label="–í—ã–∂–∏–≤—à–∏–µ")
    plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–∏–ª–µ—Ç–∞ (Fare)")
    plt.xlabel("Fare")
    plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤")
    plt.legend()
    plt.show()


def prepare_xy(df):
    #–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ X –∏ y
    y = df["Survived"]
    X = df.drop("Survived", axis=1)
    print("–ù–∞–±–æ—Ä—ã X –∏ y —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã.")
    print(f"–†–∞–∑–º–µ—Ä X: {X.shape}, —Ä–∞–∑–º–µ—Ä y: {y.shape}")
    print()
    return X, y


def split_data(X, y):
    #–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
    print("–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª—ë–Ω (75% –æ–±—É—á–µ–Ω–∏–µ, 25% —Ç–µ—Å—Ç).")
    print()
    return X_train, X_test, y_train, y_test


def train_model(X_train, y_train):
    #–û–±—É—á–µ–Ω–∏–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train, y_train)
    print("–ú–æ–¥–µ–ª—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –æ–±—É—á–µ–Ω–∞.")
    print()
    return model


def evaluate_model(model, X_test, y_test):
    #–û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    acc = accuracy_score(y_test, y_pred)
    print("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
    print(cm)
    print()
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (accuracy): {acc:.4f}")
    print()
    return acc

def main():
    print(f"Python version: {sys.version}")
    print(f"Numpy version: {np.version.version}")
    print(f"Pandas version: {pd.__version__}")
    print(f"Matplotlib version: {mpl.__version__}")
    print()

    df = load_data("data/titanic.csv")
    describe_data(df)
    df = clean_data(df)
    df = encode_sex(df)
    df = encode_embarked(df)
    df = remove_nulls(df)
    df = normalize_fare(df)
    analyze_fare(df)
    plot_fare_hist(df)
    X, y = prepare_xy(df)
    X_train, X_test, y_train, y_test = split_data(X, y)
    model = train_model(X_train, y_train)
    evaluate_model(model, X_test, y_test)

if __name__ == "__main__":
    main()

